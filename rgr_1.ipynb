{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5660d8-d330-4c8c-853d-8ebe478d1714",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1.Explain the difference between simple linear regression and multiple linear regression. Provide an example of each?\n",
    "\n",
    "ANS.\n",
    "\n",
    "Simple lenear regression:- Simple Linear Regression is a type of Regression algorithms that models the relationship between\n",
    "                           a dependent variable and a single independent variable. The relationship shown by a Simple Linear\n",
    "                           Regression model is linear or a sloped straight line, hence it is called Simple Linear Regression.\n",
    "             \n",
    "        Ex:- Relationship between Experience abd salary\n",
    "        \n",
    "Multiple lenear Regression:- Multiple Linear Regression is one of the important regression algorithms which models the linear \n",
    "                             relationship between a single dependent continuous variable and more than one independent variable.\n",
    "    \n",
    "    \n",
    "        Ex:- price prediction of house\n",
    "        \n",
    "        \n",
    "Q2.Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "   a given dataset?\n",
    "\n",
    "ANS.\n",
    "\n",
    "  There are the various types of assumptions in linear regresion \n",
    "    \n",
    "    1. Linear model:- According to this assumption, the relationship between the independent and dependent variables should \n",
    "                      be linear.\n",
    "        \n",
    "    2. No Multicollearn id the data:- High collinearity means that the two variables vary very similarly and contain the same kind\n",
    "                                      of information. This will leads to redundancy in the dataset. Due to redundancy, only the\n",
    "                                      complexity of the model increase, and no new information or pattern is learned by the model.\n",
    "            \n",
    "    3. Homoscedasticity of residuals or equal variance:- Homoscedasity is the term that states that the spread residuals which we\n",
    "                                      are getting from the linear regression model should be homogeneous or equal spaces. \n",
    "\n",
    "        \n",
    "    4. Predictors are distributed Normally:- This assumption ensures that you have equally distributed observations for the range\n",
    "                                             of each predictor. \n",
    "        \n",
    "        \n",
    "    To chech the assumption in the dataset you use Q-Q plot\n",
    "    \n",
    "       In this method, observed value and expected value are plotted on a graph.  If the plotted value vary more from a straight \n",
    "        line, then the data is not normally distributed. Otherwise data will be normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953a20d-ab60-423e-8d5b-b98a3e4c44f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "    a real-world scenario.\n",
    "    \n",
    "ANS \n",
    "\n",
    "   Slope:- slope is a ratio of the change in one variable to the change in the other\n",
    "    \n",
    "           Slope is usually represented by the variable \n",
    "\n",
    "                  m=change in y/change in x\n",
    "            \n",
    "   Intercept:- The intercept refers to the y-intercept, which is where the line intersects the y-axis. Again, other variables may\n",
    "               be used, but the intercept generally refers to the independent variable and the vertical axis.\n",
    "\n",
    "    \n",
    "     EX:- If you want to model how the cost of renting a car depends on the number of days, you can use a linear equation with \n",
    "          slope and intercept. The slope represents the rate of change of the cost per day, and the intercept represents the \n",
    "          fixed fee or deposit. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc46c51-ee7a-4536-a363-e0a490238478",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\n",
    "ANS >.\n",
    "\n",
    "    Gradient descent is an optimization algorithm used to minimize the value of a function by iteratively adjusting its parameters\n",
    "    in the direction of steepest descent.\n",
    "          Gradient descent is used to find the optimal set of parameters that minimize the loss function. It works by iteratively\n",
    "          updating the models parameters in the direction of the negative gradient of the loss function, which represents the\n",
    "            direction of steepest descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160bf42-2f6a-4730-8192-95912d5fe2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "ANS>.\n",
    "    Multiple linear regression is a regression model that estimates the relationship between a quantitative dependent variable and\n",
    "    two or more independent variables using a straight line.\n",
    "    \n",
    "         The multiple linear regression model differs from simple linear regression in that it can accommodate multiple input\n",
    "         variables. Simple linear regression only considers a single input variable and models the relationship between that\n",
    "         variable and the output variable as a straight line. Multiple linear regression, on the other hand, allows for more\n",
    "         complex relationships between the input variables and the output variable. The model can capture the combined effects \n",
    "         of multiple input variables on the output variable, allowing for more accurate predictions.                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e172b-2b71-450b-8261-165ca184db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?\n",
    "ANS>.\n",
    "Multicollinearity is a statistical phenomenon that occurs when two or more predictor variables in a multiple linear regression \n",
    "model are highly correlated with each other. It can cause problems in the estimation of regression coefficients and the prediction\n",
    "of the outcome variable.\n",
    "                      To detect multicollinearity, correlation coefficients between each pair of predictor variables can be \n",
    "                     calculated. If the correlation coefficient is high, it indicates a strong linear relationship between the two\n",
    "                     variables. A common threshold for high correlation is a correlation coefficient greater than 0.7 or 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5da72a-9382-4d7d-8758-1388cd69b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "ANS>\n",
    "\n",
    "Polynomial regression is a form of linear regression in which the relationship between the independent variable x and the dependent\n",
    "variable y is modeled as an nth degree polynomial. Polynomial regression is useful when the relationship between the variables is\n",
    "nonlinear, and cannot be adequately described by a straight line.\n",
    "                                  Linear regression models the relationship between the dependent variable and the independent\n",
    "                                  variable as a straight line, while polynomial regression models the relationship as a curve of \n",
    "                                  degree n. Polynomial regression can capture nonlinear patterns in the data, but can be more prone\n",
    "                                  to overfitting than linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a84cbf4-c825-48b5-9f51-c1707beb9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?\n",
    "ANS>\n",
    " Polynomial regression and linear regression are both forms of regression analysis that are used to model the relationship between\n",
    " a dependent variable and one or more independent variables. The advantages and disadvantages of polynomial regression compared to \n",
    " linear regression are as follows:\n",
    "        \n",
    "  Advantages of polynomial regression and linear regression:\n",
    "     1. Can capture nonlinear patterns: Polynomial regression can model nonlinear relationships between the dependent and \n",
    "        independent variables, whereas linear regression can only model linear relationships.\n",
    "        \n",
    "     2. Flexible: The degree of the polynomial can be adjusted to fit the complexity of the data.\n",
    "    \n",
    "     3. Can improve model fit: By adding higher-order polynomial terms, polynomial regression can fit the data better than linear\n",
    "        regression.\n",
    "        \n",
    "  Disadvantages of polynomial regression:\n",
    "    \n",
    "    1. Overfitting: Polynomial regression can be more prone to overfitting than linear regression, especially when the degree of \n",
    "       the polynomial is high. Overfitting occurs when the model fits the training data too closely, and does not generalize well\n",
    "       to new data.\n",
    "    \n",
    "    2. Increased complexity: The inclusion of higher-order polynomial terms increases the complexity of the model and makes it more\n",
    "       difficult to interpret.\n",
    "        \n",
    "    3. Extrapolation can be unreliable: Extrapolating beyond the range of the data can be unreliable in polynomial regression, as\n",
    "       the fitted curve may not reflect the true behavior of the relationship between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73182a00-2ab3-4887-9761-220344c24372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8103af-f923-43a6-bbac-cd8325d2cc20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
